---
title: 'æ–°æ‰‹å®æˆ˜ï¼šç”¨ PyTorch + CNN äº²æ‰‹è®­ç»ƒä¸€ä¸ªæ¶æ„ URL æ£€æµ‹æ¨¡å‹'
date: '2025-12-25'
tags: ['AI Security']
draft: false
summary: 'ç†è®ºå­¦ä¼šäº†ï¼Œæ‰‹ç—’æ€ä¹ˆåŠï¼Ÿæœ¬æ–‡æä¾›å®Œæ•´å¯è¿è¡Œçš„ä»£ç ï¼ŒåŸºäº PyTorch æ„å»ºå­—ç¬¦çº§ CNN æ¨¡å‹ï¼Œæ‰‹æŠŠæ‰‹å¸¦ä½ è·‘é€šæ¶æ„ URL æ£€æµ‹çš„è®­ç»ƒå…¨æµç¨‹ã€‚'
---

## å‰è¨€

åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº† CNN å¦‚ä½•åƒæ‹¿ç€â€œæ”¾å¤§é•œâ€ä¸€æ ·æ‰«æ URL ä¸­çš„æ¶æ„å…³é”®è¯ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬æ‹’ç»çº¸ä¸Šè°ˆå…µï¼Œç›´æ¥ä¸Šä»£ç ï¼

æˆ‘ä»¬å°†ä½¿ç”¨å¤§å®¶æœ€ç†Ÿæ‚‰çš„ **Kaggle æ•°æ®é›† (Malicious URLs dataset)**ï¼Œç”¨ PyTorch æ­å»ºä¸€ä¸ªå­—ç¬¦çº§ CNN æ¨¡å‹ã€‚

> **ğŸ¯ ç›®æ ‡**ï¼šè¾“å…¥ä¸€æ¡ URLï¼ŒAI å‘Šè¯‰ä½ å®ƒæ˜¯æ­£å¸¸ï¼ˆbenignï¼‰ã€é’“é±¼ï¼ˆphishingï¼‰ã€ç¯¡æ”¹ï¼ˆdefacementï¼‰è¿˜æ˜¯æ¶æ„è½¯ä»¶ï¼ˆmalwareï¼‰ã€‚

---

## ä¸€ã€å‡†å¤‡å·¥ä½œ

### 1.1 ç¯å¢ƒè¦æ±‚

ç¡®ä¿ä½ çš„ç”µè„‘é‡Œè£…äº†ä»¥ä¸‹ Python åº“ï¼š

```bash
pip install torch pandas scikit-learn
```

### 1.2 æ•°æ®é›†

è¯·ç¡®ä¿ä½ å·²ç»ä¸‹è½½äº†æ•°æ®é›†ï¼Œå¹¶æ”¾åœ¨äº† **`E:/dataset/malicious_phish.csv`**ã€‚

- æ•°æ®é›†é€šå¸¸åŒ…å«ä¸¤åˆ—ï¼š`url`ï¼ˆé“¾æ¥æ–‡æœ¬ï¼‰å’Œ `type`ï¼ˆæ ‡ç­¾ç±»å‹ï¼‰ã€‚

---

## äºŒã€ä»£ç å…¨è§£æ

æˆ‘ä»¬å°†ä»£ç åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†ï¼š**å­—å…¸ä¸é¢„å¤„ç†**ã€**æ•°æ®é›†åŠ è½½**ã€**æ¨¡å‹æ­å»º**ã€**è®­ç»ƒå¾ªç¯**ã€‚

### ç¬¬ä¸€æ­¥ï¼šå­—ç¬¦å­—å…¸ä¸é¢„å¤„ç†

ç”µè„‘ä¸è®¤è¯†å­—ç¬¦ï¼Œæˆ‘ä»¬è¦æŠŠ `a, b, c, .` å˜æˆ `1, 2, 3, 4`ã€‚

```python
import string

# 1. åˆ¶ä½œå­—å…¸
# string.printable åŒ…å«äº†æ•°å­—ã€å­—æ¯ã€æ ‡ç‚¹ç¬¦å·ç­‰æ‰€æœ‰å¸¸ç”¨å­—ç¬¦
ALL_CHARS = string.printable
# å»ºç«‹å­—ç¬¦åˆ°æ•°å­—çš„æ˜ å°„ï¼Œä» 1 å¼€å§‹ï¼ˆ0 ç•™ç»™å¡«å……ä½ï¼‰
char2idx = {c: i + 1 for i, c in enumerate(ALL_CHARS)}
char2idx["<PAD>"] = 0

# 2. è®¾å®šæœ€å¤§é•¿åº¦
MAX_LEN = 200

# 3. ç¼–ç å‡½æ•°
def encode_url(url):
    # æŸ¥è¡¨ï¼šå­—ç¬¦ -> æ•°å­—
    seq = [char2idx.get(c, 0) for c in url]

    # ç»Ÿä¸€é•¿åº¦ï¼šä¸å¤Ÿè¡¥0ï¼Œå¤ªé•¿æˆªæ–­
    if len(seq) < MAX_LEN:
        seq += [0] * (MAX_LEN - len(seq))
    else:
        seq = seq[:MAX_LEN]

    return seq
```

### ç¬¬äºŒæ­¥ï¼šå®šä¹‰æ•°æ®é›† (Dataset)

è¿™ä¸€æ­¥å‘Šè¯‰ PyTorch æ€ä¹ˆè¯»ä½ çš„ CSV æ–‡ä»¶ã€‚

```python
from torch.utils.data import Dataset
import pandas as pd
import torch

# æ ‡ç­¾æ˜ å°„è¡¨
label2idx = {
    "benign": 0,
    "phishing": 1,
    "defacement": 2,
    "malware": 3
}

class URLDataset(Dataset):
    def __init__(self, csv_path):
        # è¯»å– CSVï¼Œé€šè¿‡ on_bad_lines è·³è¿‡å¯èƒ½æŸåçš„è¡Œ
        self.df = pd.read_csv(csv_path, on_bad_lines='skip')

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        # è·å–ç¬¬ idx æ¡æ•°æ®
        url = str(self.df.iloc[idx]["url"]) # ç¡®ä¿è½¬ä¸ºå­—ç¬¦ä¸²
        label = self.df.iloc[idx]["type"]

        # è½¬æ¢æ•°æ®ç±»å‹
        # x æ˜¯è¾“å…¥ç‰¹å¾ (LongTensor ç”¨äº Embedding)
        x = torch.tensor(encode_url(url), dtype=torch.long)
        # y æ˜¯åˆ†ç±»æ ‡ç­¾
        y = torch.tensor(label2idx[label], dtype=torch.long)

        return x, y
```

### ç¬¬ä¸‰æ­¥ï¼šæ­å»º CNN æ¨¡å‹ (The Brain)

è¿™æ˜¯æˆ‘ä»¬çš„æ ¸å¿ƒæ¨¡å‹ã€‚

```python
import torch.nn as nn

class CNN_URL(nn.Module):
    def __init__(self, vocab_size, num_classes):
        super().__init__()

        # 1. Embedding å±‚ï¼šæŠŠæ•°å­—å˜æˆå‘é‡
        # 64 æ˜¯å‘é‡ç»´åº¦
        self.embedding = nn.Embedding(vocab_size, 64, padding_idx=0)

        # 2. å·ç§¯å±‚ï¼šæ‰«æç‰¹å¾
        # in=64 (å‘é‡ç»´åº¦), out=128 (æå–128ç§ç‰¹å¾), kernel=3 (çª—å£å¤§å°)
        self.conv1 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)

        # 3. æ± åŒ–å±‚ï¼šæå–æœ€å¼ºç‰¹å¾
        # è¿™é‡Œä½¿ç”¨ AdaptiveAvgPool (è‡ªé€‚åº”å¹³å‡æ± åŒ–)ï¼Œä¹Ÿå¯ä»¥æ¢æˆ MaxPool
        self.pool = nn.AdaptiveAvgPool1d(1)

        # 4. å…¨è¿æ¥å±‚ï¼šåˆ†ç±»
        self.fc = nn.Linear(128, num_classes)

    def forward(self, x):
        # x: [Batch, 200]
        x = self.embedding(x)      # -> [Batch, 200, 64]

        # å·ç§¯å±‚è¦æ±‚ Channel åœ¨ç¬¬ 2 ç»´ï¼Œæ‰€ä»¥éœ€è¦è½¬ç½® (Swap dims 1 and 2)
        x = x.transpose(1, 2)      # -> [Batch, 64, 200]

        x = self.conv1(x)          # -> [Batch, 128, 198]

        # æ¿€æ´»å‡½æ•° (å¢åŠ éçº¿æ€§èƒ½åŠ›)
        x = torch.relu(x)

        x = self.pool(x)           # -> [Batch, 128, 1]
        x = x.squeeze(-1)          # -> [Batch, 128] (å»æ‰å¤šä½™ç»´åº¦)

        return self.fc(x)          # -> [Batch, 4]
```

---

## ä¸‰ã€å®Œæ•´å¯è¿è¡Œè„šæœ¬

å°†æ‰€æœ‰ç§¯æœ¨æ‹¼åœ¨ä¸€èµ·ï¼ŒåŠ ä¸Šè®­ç»ƒå¾ªç¯ï¼ˆTraining Loopï¼‰ã€‚ä½ å¯ä»¥ç›´æ¥å¤åˆ¶è¿™æ®µä»£ç åˆ°ä¸€ä¸ª `.py` æ–‡ä»¶ä¸­è¿è¡Œã€‚

```python
import string
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split
import time

# --- é…ç½®å‚æ•° ---
CSV_PATH = "E:/dataset/malicious_phish.csv" # ä½ çš„æ–‡ä»¶è·¯å¾„
BATCH_SIZE = 64
LR = 0.001
EPOCHS = 5
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(f"æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {DEVICE}")

# --- 1. é¢„å¤„ç† ---
ALL_CHARS = string.printable
char2idx = {c: i + 1 for i, c in enumerate(ALL_CHARS)}
char2idx["<PAD>"] = 0
MAX_LEN = 200

def encode_url(url):
    seq = [char2idx.get(c, 0) for c in url]
    if len(seq) < MAX_LEN:
        seq += [0] * (MAX_LEN - len(seq))
    else:
        seq = seq[:MAX_LEN]
    return seq

label2idx = {"benign": 0, "phishing": 1, "defacement": 2, "malware": 3}

# --- 2. æ•°æ®é›† ---
class URLDataset(Dataset):
    def __init__(self, csv_path):
        # ä»…è¯»å–éƒ¨åˆ†æ•°æ®ç”¨äºå¿«é€Ÿæ¼”ç¤ºï¼Œå®é™…è·‘å¯ä»¥å»æ‰ nrows
        # self.df = pd.read_csv(csv_path, nrows=50000)
        self.df = pd.read_csv(csv_path)

    def __len__(self):
        return len(self.df)
    def __getitem__(self, idx):
        url = str(self.df.iloc[idx]["url"])
        label = self.df.iloc[idx]["type"]
        x = torch.tensor(encode_url(url), dtype=torch.long)
        y = torch.tensor(label2idx[label], dtype=torch.long)
        return x, y

# --- 3. æ¨¡å‹ ---
class CNN_URL(nn.Module):
    def __init__(self, vocab_size, num_classes):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, 64, padding_idx=0)
        self.conv1 = nn.Conv1d(64, 128, kernel_size=3)
        self.pool = nn.AdaptiveAvgPool1d(1) # æˆ–è€… nn.AdaptiveMaxPool1d(1)
        self.fc = nn.Linear(128, num_classes)
        self.relu = nn.ReLU() # æ˜¾å¼å®šä¹‰æ¿€æ´»å‡½æ•°

    def forward(self, x):
        x = self.embedding(x)
        x = x.transpose(1, 2)
        x = self.conv1(x)
        x = self.relu(x)
        x = self.pool(x).squeeze(-1)
        return self.fc(x)

# --- 4. ä¸»ç¨‹åº ---
if __name__ == "__main__":
    # åŠ è½½æ•°æ®
    print("æ­£åœ¨è¯»å–æ•°æ®...")
    full_dataset = URLDataset(CSV_PATH)

    # åˆ’åˆ†è®­ç»ƒé›†(80%) å’Œ æµ‹è¯•é›†(20%)
    train_size = int(0.8 * len(full_dataset))
    test_size = len(full_dataset) - train_size
    train_ds, test_ds = random_split(full_dataset, [train_size, test_size])

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)

    # åˆå§‹åŒ–æ¨¡å‹
    vocab_size = len(char2idx) + 1
    num_classes = 4
    model = CNN_URL(vocab_size, num_classes).to(DEVICE)

    # æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    # å¼€å§‹è®­ç»ƒ
    print("å¼€å§‹è®­ç»ƒ CNN æ¨¡å‹...")
    for epoch in range(EPOCHS):
        start_time = time.time()
        model.train() # è®­ç»ƒæ¨¡å¼
        total_loss = 0

        for x, y in train_loader:
            x, y = x.to(DEVICE), y.to(DEVICE)

            optimizer.zero_grad()   # æ¢¯åº¦å½’é›¶
            outputs = model(x)      # å‰å‘ä¼ æ’­
            loss = criterion(outputs, y) # è®¡ç®—æŸå¤±
            loss.backward()         # åå‘ä¼ æ’­
            optimizer.step()        # æ›´æ–°å‚æ•°

            total_loss += loss.item()

        # æ¯ä¸ª Epoch ç»“æŸåæµ‹è¯•ä¸€ä¸‹å‡†ç¡®ç‡
        model.eval() # è¯„ä¼°æ¨¡å¼
        correct = 0
        total = 0
        with torch.no_grad():
            for x, y in test_loader:
                x, y = x.to(DEVICE), y.to(DEVICE)
                outputs = model(x)
                _, predicted = torch.max(outputs.data, 1)
                total += y.size(0)
                correct += (predicted == y).sum().item()

        acc = 100 * correct / total
        print(f"Epoch [{epoch+1}/{EPOCHS}] | "
              f"Loss: {total_loss/len(train_loader):.4f} | "
              f"Test Acc: {acc:.2f}% | "
              f"Time: {time.time()-start_time:.1f}s")

    print("è®­ç»ƒå®Œæˆï¼")

    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), "cnn_url_model.pth")
    print("æ¨¡å‹å·²ä¿å­˜ä¸º cnn_url_model.pth")
```

---

## å››ã€å†™åœ¨æœ€åï¼šæ–°æ‰‹é¿å‘æŒ‡å—

1.  **æ–‡ä»¶è·¯å¾„**ï¼šä»£ç é‡Œå†™çš„æ˜¯ `E:/dataset/malicious_phish.csv`ï¼Œè¯·åŠ¡å¿…ç¡®è®¤ä½ çš„æ–‡ä»¶åå’Œè·¯å¾„å®Œå…¨ä¸€è‡´ï¼Œæ³¨æ„æ–œæ æ–¹å‘ `/`ã€‚
2.  **æ˜¾å­˜é—®é¢˜**ï¼šå¦‚æœä½ åœ¨ GPU ä¸Šè·‘å‡ºç° `Out of memory`ï¼Œè¯·æŠŠ `BATCH_SIZE` æ”¹å°ä¸€ç‚¹ï¼ˆæ¯”å¦‚æ”¹åˆ° 32 æˆ– 16ï¼‰ã€‚
3.  **CPU ä¹Ÿèƒ½è·‘**ï¼šæ²¡æœ‰æ˜¾å¡æ²¡å…³ç³»ï¼Œä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹ä½¿ç”¨ CPUï¼Œåªæ˜¯ç¨å¾®æ…¢ä¸€ç‚¹ç‚¹ï¼Œå–æ¯å’–å•¡å°±å¥½äº†ã€‚
4.  **å‡†ç¡®ç‡**ï¼šå¯¹äºè¿™ä¸ªæ•°æ®é›†ï¼Œç®€å•çš„ CNN é€šå¸¸èƒ½å¾ˆå¿«è¾¾åˆ° 90% ä»¥ä¸Šçš„å‡†ç¡®ç‡ã€‚å¦‚æœä½ çš„å‡†ç¡®ç‡å¾ˆä½ï¼Œæ£€æŸ¥ä¸€ä¸‹æ•°æ®é›†çš„æ ‡ç­¾åˆ†å¸ƒæ˜¯å¦å¹³è¡¡ã€‚

å¿«å»è¿è¡Œä»£ç ï¼Œäº«å—ä½ çš„ç¬¬ä¸€ä¸ª AI å®‰å…¨æ¨¡å‹å§ï¼
